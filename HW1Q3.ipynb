{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyaJcHo6zzL+3daJFeWhgr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hj151mids/AIPI-531/blob/main/HW1Q3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zcck5Z1zKWux",
        "outputId": "cba74be7-46ec-477a-d086-2b8159a7e13e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the library directly from Google Drive"
      ],
      "metadata": {
        "id": "-oxbJzXlZhb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install '/content/drive/MyDrive/stable-baselines3'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7S0Hor_PtOm",
        "outputId": "cd9ee3e7-08cf-438a-fece-4192c2b3aa5a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./drive/MyDrive/stable-baselines3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gym==0.21\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from stable-baselines3==1.8.0a4) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.8/dist-packages (from stable-baselines3==1.8.0a4) (1.13.1+cu116)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from stable-baselines3==1.8.0a4) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from stable-baselines3==1.8.0a4) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from stable-baselines3==1.8.0a4) (3.2.2)\n",
            "Collecting importlib-metadata~=4.13\n",
            "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata~=4.13->stable-baselines3==1.8.0a4) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.11->stable-baselines3==1.8.0a4) (4.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3==1.8.0a4) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3==1.8.0a4) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3==1.8.0a4) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3==1.8.0a4) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->stable-baselines3==1.8.0a4) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->stable-baselines3==1.8.0a4) (1.15.0)\n",
            "Building wheels for collected packages: stable-baselines3, gym\n",
            "  Building wheel for stable-baselines3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stable-baselines3: filename=stable_baselines3-1.8.0a4-py3-none-any.whl size=173060 sha256=428f56e11719e1ab56700267a7ffff04edaa3e3387dc980ca36953816b3f5126\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/e3/f8/2df5472d5ad64e8eec232e58b29f95bf995c73f8d5afcebffb\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616826 sha256=d13f651d0fb224ed6980e67232a727e001b797835311bae98ba7edd17529d8f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/6d/b3/a3a6e10704795c9b9000f1ab2dc480dfe7bed42f5972806e73\n",
            "Successfully built stable-baselines3 gym\n",
            "Installing collected packages: importlib-metadata, gym, stable-baselines3\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 6.0.0\n",
            "    Uninstalling importlib-metadata-6.0.0:\n",
            "      Successfully uninstalled importlib-metadata-6.0.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed gym-0.21.0 importlib-metadata-4.13.0 stable-baselines3-1.8.0a4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.ppo import MlpPolicy"
      ],
      "metadata": {
        "id": "kcfSyHBVQKNK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up the models and test different gae_lambda parameters"
      ],
      "metadata": {
        "id": "P0S8rheSZkvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the game using Classic Advantange (Monte Carlo Method)\n",
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "model = A2C(MlpPolicy, env, verbose=0, gae_lambda = 1)\n",
        "\n",
        "model.learn(total_timesteps=10000)\n",
        "\n",
        "eval_env = gym.make('CartPole-v1')\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjhqTRI8TB56",
        "outputId": "ee5117a4-f7b6-4c76-c1a6-79f9b1d06493"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:500.00 +/- 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the game using Classic Advantange (Vanilla Method)\n",
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "model = A2C(MlpPolicy, env, verbose=0, gae_lambda = 0)\n",
        "\n",
        "model.learn(total_timesteps=10000)\n",
        "\n",
        "eval_env = gym.make('CartPole-v1')\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_DukelZYaAG",
        "outputId": "cea48f38-3939-4c42-b6d4-044a8df837d3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:9.34 +/- 0.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the game using Classic Advantange (n-step GAE Method)\n",
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "model = A2C(MlpPolicy, env, verbose=0, gae_lambda = 0.5)\n",
        "\n",
        "model.learn(total_timesteps=10000)\n",
        "\n",
        "eval_env = gym.make('CartPole-v1')\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz_SBdi0Yr5w",
        "outputId": "6951c0fb-5326-452a-c52b-1a7f54fe04df"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:128.60 +/- 13.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From what we have observed, the MC advantage will output the highest mean reward of A2C model."
      ],
      "metadata": {
        "id": "l6WBZGNmZXIU"
      }
    }
  ]
}